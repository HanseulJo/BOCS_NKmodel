{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BO_on_NKmodel_game.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPdG78Hc1OptyoBz2pL6NfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanseulJo/BOCS_NKmodel/blob/master/BO_on_NKmodel_game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPQlESt7nj0d"
      },
      "source": [
        "Original codes: `https://github.com/HanseulJo/BOCS_NKmodel.git`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQnMazltSkT3"
      },
      "source": [
        "# Dependencies (Bind it all, Run it all!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTSAVg3JjX9"
      },
      "source": [
        "import os, sys, time, itertools\n",
        "\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from easydict import EasyDict\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq43AJ7CS5B5"
      },
      "source": [
        "\"\"\"\n",
        "Author: Hanseul Cho\n",
        "Date: 2021.08.04\n",
        "\"\"\"\n",
        "# Helper functions\n",
        "def flip(state, ind):\n",
        "    \"\"\" given a state (in numpy array), flip (0 <-> 1) a digit \"\"\"\n",
        "    assert state.ndim == 1, state.ndim\n",
        "    new_state = state.copy()\n",
        "    new_state[ind] = 1-new_state[ind]\n",
        "    return new_state\n",
        "\n",
        "def neighbors(state):\n",
        "    \"\"\" given a state (in numpy array), return a 2D array whose rows are neighbors of the state \"\"\"\n",
        "    return np.stack([flip(state, i) for i in range(len(state))])\n",
        "\n",
        "# Class object of NKmodel\n",
        "class NKmodel(object):\n",
        "    \"\"\"\n",
        "    NKmodel class. A single NK model.\n",
        "    Huge thanks to https://github.com/elplatt/nkmodel.git\n",
        "    \n",
        "    <PARAM>\n",
        "    N: the number of loci\n",
        "    K: the number of the other dependent loci for each locus (0 <= K <= N-1)\n",
        "    A: the number of states that each locus can have (e.g.: 2 for binary variables)\n",
        "    <attributes>\n",
        "    self.interdependence : interdependency matrix in 2D boolean numpy array.\n",
        "    self.contributions   : list of dict's - ith dict maps (tuple (x_i, x_i0, x_i1, ..., x_iK) of length K) |--> (contribution(=payoff) f_i(x))\n",
        "    \"\"\"\n",
        "    def __init__(self, N, K, A=2, interdependence=None, contributions=None, random_seeds=(None, None)):\n",
        "        assert 0 <= K <= N-1\n",
        "        self.N, self.K, self.A = N, K, A\n",
        "        if interdependence is None:\n",
        "            # randomly generated interdependence matrix\n",
        "            self.interdependence = np.full((N,N), False)\n",
        "            rng_state_dep = np.random.RandomState(seed=random_seeds[0])\n",
        "            for i in range(N):\n",
        "                dependence = [i] + list(rng_state_dep.choice(list(set(range(N)) - set([i])), size=K, replace=False))\n",
        "                self.interdependence[i][dependence] = True\n",
        "        else:\n",
        "            self.interdependence = interdependence\n",
        "        if contributions is None:\n",
        "            self.contributions = [{} for _ in range(N)]\n",
        "            rng_state_ctrb = np.random.RandomState(seed=random_seeds[1])\n",
        "            for i in range(N):\n",
        "                for label in itertools.product(range(A), repeat=K+1):  # K+1 subcollection of loci values that effects the locus i\n",
        "                    self.contributions[i][label] = float(rng_state_ctrb.random())  # float [0, 1)\n",
        "        else:\n",
        "            self.contributions = contributions\n",
        "\n",
        "    def _calculate_ith_contribution(self, state, i):\n",
        "        assert i in range(self.N), i\n",
        "        assert type(state) == np.ndarray, type(state)\n",
        "        interdep = self.interdependence[i].copy()\n",
        "        interdep[i] = False\n",
        "        label = tuple([state[i]] + list(state[interdep]))  # the value of i-th locus should be the first entry of the 'label'.\n",
        "        return self.contributions[i][label]\n",
        "\n",
        "    def fitness_and_contributions(self, state, negative=False):\n",
        "        \"\"\"\n",
        "        Given a state(: a tuple/string of length N), \n",
        "        Return fitness value and a list of contributions of each loci.\n",
        "        \"\"\"\n",
        "        if type(state) == str:\n",
        "            state = np.array([int(state[i]) for i in range(self.N)])\n",
        "        else:\n",
        "            state = np.array(state)\n",
        "        ctrbs = [self._calculate_ith_contribution(state, i) for i in range(self.N)]\n",
        "        fitness_value = sum(ctrbs) / self.N  # averaged fitness value --> btw 0 ~ 1\n",
        "        if negative:\n",
        "            fitness_value = -fitness_value\n",
        "        return fitness_value, ctrbs\n",
        "    \n",
        "    def fitness(self, state, negative=False):\n",
        "        f, _ = self.fitness_and_contributions(state, negative=negative)\n",
        "        return f\n",
        "    \n",
        "    def evaluate(self, state, negative=False):\n",
        "        if state.ndim == 1:\n",
        "            state = np.expand_dims(state, axis=0)\n",
        "        assert state.shape[1] == self.N, state.shape[1]\n",
        "        return np.array([self.fitness(state[i], negative=negative) for i in range(state.shape[0])])\n",
        "    \n",
        "    def fitness_and_contrib_diff(self, state_prev, flip_ind, fitness_prev=None, ctrbs_prev=None, negative=False):\n",
        "        state_new = flip(state_prev, flip_ind)\n",
        "        depend_on_flip = self.interdependence[:,flip_ind]\n",
        "        if fitness_prev is None or ctrbs_prev is None:\n",
        "            fitness_prev, ctrbs_prev = self.fitness_and_contributions(state_prev, negative=negative)\n",
        "        fitness_new = fitness_prev * self.N\n",
        "        ctrbs_diff = np.zeros(self.N)\n",
        "        for j in np.nonzero(depend_on_flip)[0]:\n",
        "            ctrb_new_j = self._calculate_ith_contribution(state_new, j)\n",
        "            ctrb_prev_j = ctrbs_prev[j]\n",
        "            fitness_new = fitness_new - ctrb_prev_j + ctrb_new_j\n",
        "            ctrbs_diff[j] = ctrb_new_j - ctrb_prev_j\n",
        "        fitness_new /= self.N\n",
        "        return fitness_new, ctrbs_diff\n",
        "\n",
        "    def landscape(self, negative=False):\n",
        "        \"\"\"\n",
        "        Return a dictionary mapping each state to its fitness value. (Naive algorithm)\n",
        "        \"\"\"\n",
        "        landscape_dic = {}\n",
        "        states = itertools.product(range(self.A), repeat=self.N)\n",
        "        for state in states:\n",
        "            landscape_dic[state] = self.fitness(state, negative=negative)\n",
        "        return landscape_dic\n",
        "\n",
        "    def landscape_with_contributions(self):\n",
        "        \"\"\"\n",
        "        Return a dictionary mapping each state to its fitness value and contributions of loci. (Naive algorithm)\n",
        "        \"\"\"\n",
        "        return {state: self.fitness_and_contributions(state) for state in itertools.product(range(self.A), repeat=self.N)}  # along all possible states\n",
        "\n",
        "    def get_global_optimum(self, negative=False, anti_opt=False, cache=False, given_landscape=None):\n",
        "        \"\"\"\n",
        "        Global maximum fitness value and its maximizer(state), in a NAIVE way.\n",
        "        If \"anti_opt=True\", this returns the \"minimum\" fitness value and \"minimizer\". \n",
        "        \"\"\"\n",
        "        landscape = self.landscape() if given_landscape is None else given_landscape\n",
        "        optimum = max(landscape.values()) if not anti_opt else min(landscape.values())\n",
        "        states = [s for s in landscape.keys() if landscape[s] == optimum]\n",
        "        if negative:\n",
        "            optimum = -optimum\n",
        "        if cache:\n",
        "            return optimum, states, landscape\n",
        "        else:\n",
        "            return optimum, states\n",
        "        \n",
        "    def get_optimum_and_more(self, order, negative=False, anti_opt=False, cache=False, given_landscape=None):\n",
        "        \"\"\"\n",
        "        First several maximum fitness values and their maximizers(states), in a NAIVE way.\n",
        "        If \"anti_opt=True\", this returns first several \"minimum\" fitness values and \"minimizers\". \n",
        "        \"\"\"\n",
        "        landscape = self.landscape() if given_landscape is None else given_landscape\n",
        "        landscape_list = sorted(landscape.items(), key=lambda x: -x[1])\n",
        "        if anti_opt:\n",
        "            landscape_list.reverse()\n",
        "        state_opt, fit_opt = landscape_list[0]\n",
        "        if negative:\n",
        "            fit_opt = -fit_opt\n",
        "        optima2states = [{\"fitness\": fit_opt, \"states\":[state_opt]}]\n",
        "        cnt = 1\n",
        "        for state, fitness in landscape_list[1:]:\n",
        "            if negative:\n",
        "                fitness = -fitness\n",
        "            if fitness == optima2states[-1][\"fitness\"]:\n",
        "                optima2states[-1][\"states\"].append(state)\n",
        "            else:\n",
        "                cnt += 1\n",
        "                if cnt > order:\n",
        "                    break\n",
        "                optima2states.append({\"fitness\": fitness, \"states\":[state]})\n",
        "        if cache:\n",
        "            return optima2states, landscape\n",
        "        else:\n",
        "            return optima2states\n",
        "    \n",
        "    def print_info(self, path=None, order=10):\n",
        "        optlist = self.get_optimum_and_more(order)\n",
        "        if path is None:\n",
        "            print(\"\\nInterdependence Matrix:\")\n",
        "            for i in range(self.N):\n",
        "                print(\"\".join([\"X\" if b else \"O\" for b in self.interdependence[i]]))\n",
        "            print(\"\\nLandscape:\")\n",
        "            d = self.landscape_with_contributions()\n",
        "            for state, (fit, ctrbs) in d.items():\n",
        "                ctrbs = [str(round(v, 4)) for v in ctrbs]\n",
        "                fit = str(round(fit, 4))\n",
        "                state = \"\".join([str(x) for x in state])\n",
        "                print(\"\\t\".join([state] + ctrbs + [fit]))\n",
        "            for i in range(order):\n",
        "                opt, optstates = optlist[i][\"fitness\"], optlist[i][\"states\"]\n",
        "                print(f\"{i+1}-th optimum: {opt} {optstates}\")\n",
        "        else:\n",
        "            with open(path + \"/knowledge.txt\", \"w\") as f1:\n",
        "                for i in range(self.N):\n",
        "                    print(\"\".join([\"X\" if b else \"O\" for b in self.interdependence[i]]), file=f1)\n",
        "            with open(path + \"/landscape.txt\", \"w\") as f2:\n",
        "                d = self.landscape_with_contributions()\n",
        "                for state, (fit, ctrbs) in d.items():\n",
        "                    ctrbs = [str(round(v, 4)) for v in ctrbs]\n",
        "                    fit = str(round(fit, 4))\n",
        "                    state = \"\".join([str(x) for x in state])\n",
        "                    print(\"\\t\".join([state] + ctrbs + [fit]), file=f2)\n",
        "            with open(path + \"/rankboard.txt\", \"w\") as f3:\n",
        "                for i in range(order):\n",
        "                    opt, optstates = optlist[i][\"fitness\"], optlist[i][\"states\"]\n",
        "                    print(f\"{i+1}-th optimum: {opt} {optstates}\", file=f3)\n",
        "\n",
        "\n",
        "# Fuctions to generate random seeds for NKmodel\n",
        "def _generate_random_seeds(seed_str, n_im_seed=3, n_ctrbs_seed=3, n_init_point_seed=3):\n",
        "    \"\"\"\n",
        "    Original code: COMBO.experiments.random_seed_config.py\n",
        "    \"\"\"\n",
        "    rng_state = np.random.RandomState(seed=sum([ord(ch) for ch in seed_str]))\n",
        "    result = {}\n",
        "    for _ in range(n_im_seed):\n",
        "        result[rng_state.randint(0, 10000)] = (list(rng_state.randint(0, 10000, (n_ctrbs_seed,))), list(rng_state.randint(0, 10000, (n_init_point_seed,))))\n",
        "    return result\n",
        "\n",
        "def generate_random_seeds_nkmodel():\n",
        "    \"\"\"\n",
        "    Original code: COMBO.experiments.random_seed_config.py\n",
        "    \"\"\"\n",
        "    return _generate_random_seeds(seed_str=\"NK_MODEL\", n_im_seed=100, n_ctrbs_seed=100, n_init_point_seed=100)\n",
        "\n",
        "\n",
        "# Easy Construction of NKmodel\n",
        "def Construct_NKmodel(kwargs, im_seed_num=None, ctrbs_seed_num=None, verbose=False):\n",
        "\n",
        "    if im_seed_num is None:\n",
        "        im_seed_num = np.random.randint(100)\n",
        "    if ctrbs_seed_num is None:\n",
        "        ctrbs_seed_num = np.random.randint(100)\n",
        "    \n",
        "    # Random Seed for NKmodel\n",
        "    random_seeds = generate_random_seeds_nkmodel()\n",
        "    im_seed_ = sorted(random_seeds.keys())[im_seed_num]\n",
        "    ctrbs_seed_list_, _ = sorted(random_seeds[im_seed_])\n",
        "    ctrbs_seed_ = ctrbs_seed_list_[ctrbs_seed_num]\n",
        "\n",
        "    # Create NK model\n",
        "    nkmodel = NKmodel(kwargs['N'], kwargs['K'], A=kwargs['A'], random_seeds=(im_seed_, ctrbs_seed_))\n",
        "\n",
        "    # Miscelleneous\n",
        "    if verbose:\n",
        "        print(f\"im_seed_num {im_seed_num} ctrbs_seed_num {ctrbs_seed_num}\")\n",
        "\n",
        "    return nkmodel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnUQIavsTAbj"
      },
      "source": [
        "# Author: Ricardo Baptista and Matthias Poloczek\n",
        "# Date:   June 2018\n",
        "#\n",
        "# See LICENSE.md for copyright information\n",
        "# Brought from BOCS github repo. (HanseulJo)\n",
        "\n",
        "def bhs(Xorg, yorg, nsamples, burnin, thin):\n",
        "    # Implementation of the Bayesian horseshoe linear regression hierarchy.\n",
        "    # Parameters:\n",
        "    #   Xorg     = regressor matrix [n x p]\n",
        "    #   yorg     = response vector  [n x 1]\n",
        "    #   nsamples = number of samples for the Gibbs sampler (nsamples > 0)\n",
        "    #   burnin   = number of burnin (burnin >= 0)\n",
        "    #   thin     = thinning (thin >= 1)\n",
        "    #\n",
        "    # Returns:\n",
        "    #   beta     = regression parameters  [p x nsamples]\n",
        "    #   b0       = regression param. for constant [1 x nsamples]\n",
        "    #   s2       = noise variance sigma^2 [1 x nsamples]\n",
        "    #   t2       = hypervariance tau^2    [1 x nsamples]\n",
        "    #   l2       = hypervariance lambda^2 [p x nsamples]\n",
        "    #  \n",
        "    #\n",
        "    # Example:\n",
        "    # % Load a dataset:\n",
        "    # load hald;        \n",
        "    # % Run horseshoe sampler. Normalising the data is not required.\n",
        "    # [beta, b0] = bhs(ingredients, heat, 1000, 100, 10);    \n",
        "    # % Plot the samples of the regression coefficients:\n",
        "    # boxplot(beta', 'labels', {'tricalcium aluminate','tricalcium silicate',...\n",
        "    #   'tetracalcium aluminoferrite', 'beta-dicalcium silicate'});\n",
        "    # title('Bayesian linear regression with the horseshoe hierarchy');\n",
        "    # xlabel('Predictors');\n",
        "    # ylabel('Beta');\n",
        "    # grid;\n",
        "    #\n",
        "    #\n",
        "    # References:\n",
        "    # A simple sampler for the horseshoe estimator\n",
        "    # E. Makalic and D. F. Schmidt\n",
        "    # arXiv:1508.03884, 2015\n",
        "    #\n",
        "    # The horseshoe estimator for sparse signals\n",
        "    # C. M. Carvalho, N. G. Polson and J. G. Scott\n",
        "    # Biometrika, Vol. 97, No. 2, pp. 465--480, 2010\n",
        "    #\n",
        "    # (c) Copyright Enes Makalic and Daniel F. Schmidt, 2015\n",
        "    # Adapted to python by Ricardo Baptista, 2018\n",
        "\n",
        "    n, p = Xorg.shape\n",
        "\n",
        "    # Normalize data\n",
        "    X, _, _, y, muY = standardise(Xorg, yorg)\n",
        "\n",
        "    # Return values\n",
        "    beta = np.zeros((p, nsamples))\n",
        "    s2 = np.zeros((1, nsamples))\n",
        "    t2 = np.zeros((1, nsamples))\n",
        "    l2 = np.zeros((p, nsamples))\n",
        "\n",
        "    # Initial values\n",
        "    sigma2  = 1.\n",
        "    lambda2 = np.random.uniform(size=p)\n",
        "    tau2    = 1.\n",
        "    nu      = np.ones(p)\n",
        "    xi      = 1.\n",
        "\n",
        "    # pre-compute X'*X (used with fastmvg_rue)\n",
        "    XtX = np.matmul(X.T,X)  \n",
        "\n",
        "    # Gibbs sampler\n",
        "    k = 0\n",
        "    iter = 0\n",
        "    while(k < nsamples):\n",
        "\n",
        "        # Sample from the conditional posterior distribution\n",
        "        sigma = np.sqrt(sigma2)\n",
        "        Lambda_star = tau2 * np.diag(lambda2)\n",
        "        # Determine best sampler for conditional posterior of beta's\n",
        "        if (p > n) and (p > 200):\n",
        "            b = fastmvg(X/sigma, y/sigma, sigma2*Lambda_star)\n",
        "        else:\n",
        "            b = fastmvg_rue(X/sigma, XtX/sigma2, y/sigma, sigma2*Lambda_star)\n",
        "\n",
        "        # Sample sigma2\n",
        "        e = y - np.dot(X,b)\n",
        "        shape = (n + p) / 2.\n",
        "        scale = np.dot(e.T,e)/2. + np.sum(b**2/lambda2)/tau2/2.\n",
        "        sigma2 = 1. / np.random.gamma(shape, 1./scale)\n",
        "\n",
        "        # Sample lambda2\n",
        "        scale = 1./nu + b**2./2./tau2/sigma2\n",
        "        lambda2 = 1. / np.random.exponential(1./scale)\n",
        "\n",
        "        # Sample tau2\n",
        "        shape = (p + 1.)/2.\n",
        "        scale = 1./xi + np.sum(b**2./lambda2)/2./sigma2\n",
        "        tau2 = 1. / np.random.gamma(shape, 1./scale)\n",
        "\n",
        "        # Sample nu\n",
        "        scale = 1. + 1./lambda2\n",
        "        nu = 1. / np.random.exponential(1./scale)\n",
        "\n",
        "        # Sample xi\n",
        "        scale = 1. + 1./tau2\n",
        "        xi = 1. / np.random.exponential(1./scale)\n",
        "\n",
        "        # Store samples\n",
        "        iter = iter + 1;\n",
        "        if iter > burnin:\n",
        "            # thinning\n",
        "            if (iter % thin) == 0:\n",
        "                beta[:,k] = b\n",
        "                s2[:,k]   = sigma2\n",
        "                t2[:,k]   = tau2\n",
        "                l2[:,k]   = lambda2\n",
        "                k         = k + 1\n",
        "\n",
        "    # Re-scale coefficients\n",
        "    #div_vector = np.vectorize(np.divide)\n",
        "    #beta = div_vector(beta.T, normX)\n",
        "    #b0 = muY-np.dot(muX,beta)\n",
        "    b0 = muY\n",
        "\n",
        "    return (beta, b0, s2, t2, l2)\n",
        "\n",
        "def fastmvg(Phi, alpha, D):\n",
        "    # Fast sampler for multivariate Gaussian distributions (large p, p > n) of \n",
        "    #  the form N(mu, S), where\n",
        "    #       mu = S Phi' y\n",
        "    #       S  = inv(Phi'Phi + inv(D))\n",
        "    # Reference: \n",
        "    #   Fast sampling with Gaussian scale-mixture priors in high-dimensional \n",
        "    #   regression, A. Bhattacharya, A. Chakraborty and B. K. Mallick\n",
        "    #   arXiv:1506.04778\n",
        "\n",
        "    n, p = Phi.shape\n",
        "\n",
        "    d = np.diag(D)\n",
        "    u = np.random.randn(p) * np.sqrt(d)\n",
        "    delta = np.random.randn(n)\n",
        "    v = np.dot(Phi,u) + delta\n",
        "    #w = np.linalg.solve(np.matmul(np.matmul(Phi,D),Phi.T) + np.eye(n), alpha - v)\n",
        "    #x = u + np.dot(D,np.dot(Phi.T,w))\n",
        "    mult_vector = np.vectorize(np.multiply)\n",
        "    Dpt = mult_vector(Phi.T, d[:,np.newaxis])\n",
        "    w = np.linalg.solve(np.matmul(Phi,Dpt) + np.eye(n), alpha - v)\n",
        "    x = u + np.dot(Dpt,w)\n",
        "\n",
        "    return x\n",
        "\n",
        "def fastmvg_rue(Phi, PtP, alpha, D):\n",
        "    # Another sampler for multivariate Gaussians (small p) of the form\n",
        "    #  N(mu, S), where\n",
        "    #  mu = S Phi' y\n",
        "    #  S  = inv(Phi'Phi + inv(D))\n",
        "    #\n",
        "    # Here, PtP = Phi'*Phi (X'X is precomputed)\n",
        "    #\n",
        "    # Reference:\n",
        "    #   Rue, H. (2001). Fast sampling of gaussian markov random fields. Journal\n",
        "    #   of the Royal Statistical Society: Series B (Statistical Methodology) \n",
        "    #   63, 325-338\n",
        "\n",
        "    p = Phi.shape[1]\n",
        "    Dinv = np.diag(1./np.diag(D))\n",
        "\n",
        "    # regularize PtP + Dinv matrix for small negative eigenvalues\n",
        "    try:\n",
        "        L = np.linalg.cholesky(PtP + Dinv)\n",
        "    except:\n",
        "        mat  = PtP + Dinv\n",
        "        Smat = (mat + mat.T)/2.\n",
        "        maxEig_Smat = np.max(np.linalg.eigvals(Smat))\n",
        "        L = np.linalg.cholesky(Smat + maxEig_Smat*1e-15*np.eye(Smat.shape[0]))\n",
        "\n",
        "    v = np.linalg.solve(L, np.dot(Phi.T,alpha))\n",
        "    m = np.linalg.solve(L.T, v)\n",
        "    w = np.linalg.solve(L.T, np.random.randn(p))\n",
        "\n",
        "    x = m + w\n",
        "\n",
        "    return x\n",
        "\n",
        "def standardise(X, y):\n",
        "    # Standardize the covariates to have zero mean and x_i'x_i = 1\n",
        "\n",
        "    # set params\n",
        "    n = X.shape[0]\n",
        "    meanX = np.mean(X, axis=0)\n",
        "    stdX  = np.std(X, axis=0) * np.sqrt(n)\n",
        "\n",
        "    # Standardize X's\n",
        "    #sub_vector = np.vectorize(np.subtract)\n",
        "    #X = sub_vector(X, meanX)\n",
        "    #div_vector = np.vectorize(np.divide)\n",
        "    #X = div_vector(X, stdX)\n",
        "\n",
        "    # Standardize y's\n",
        "    meany = np.mean(y)\n",
        "    y = y - meany\n",
        "\n",
        "    return (X, meanX, stdX, y, meany)\n",
        "\n",
        "# -- END OF FILE --"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JYO5pk4TG8F"
      },
      "source": [
        "# Author: Ricardo Baptista and Matthias Poloczek\n",
        "# Modified by HanseulJo\n",
        "# Date:   June 2018\n",
        "#\n",
        "# See LICENSE.md for copyright information\n",
        "#\n",
        "\n",
        "class LinReg:\n",
        "\n",
        "\tdef __init__(self, order):\n",
        "\t\t# Old name: __init__(self, nVars, order)\n",
        "\t\tself.order = order\n",
        "\n",
        "\t# ---------------------------------------------------------\n",
        "\t# ---------------------------------------------------------\n",
        "\n",
        "\tdef setupData(self):\n",
        "\n",
        "\t\t# limit data to unique points\n",
        "\t\tX, x_idx = np.unique(self.xTrain, axis=0, return_index=True)\n",
        "\t\ty = self.yTrain[x_idx]\n",
        "\n",
        "\t\t# set upper threshold\n",
        "\t\tinfT = 1e6\n",
        "\n",
        "\t\t# separate samples based on Inf output\n",
        "\t\ty_Infidx  = np.where(np.abs(y) > infT)[0]\n",
        "\t\ty_nInfidx = np.setdiff1d(np.arange(len(y)), y_Infidx)\n",
        "\n",
        "\t\t# save samples in two sets of variables\n",
        "\t\tself.xInf = X[y_Infidx,:]\n",
        "\t\tself.yInf = y[y_Infidx]\n",
        "\n",
        "\t\tself.xTrain = X[y_nInfidx,:]\n",
        "\t\tself.yTrain = y[y_nInfidx]\n",
        "\n",
        "\t# ---------------------------------------------------------\n",
        "\t# ---------------------------------------------------------\n",
        "\n",
        "\tdef fit(self, x_vals, y_vals):\n",
        "\t\t# Old name: train(self, inputs)\n",
        "\n",
        "\t\t# Set nGibbs (Gibbs iterations to run)\n",
        "\t\tnGibbs = int(1e3)\n",
        "\n",
        "\t\t# set data\n",
        "\t\tself.xTrain = x_vals.copy()\n",
        "\t\tself.yTrain = y_vals.copy()\n",
        "\n",
        "\t\t# setup data for training\n",
        "\t\tself.setupData()\n",
        "\n",
        "\t\t# create matrix with all covariates based on order\n",
        "\t\tself.xTrain = self.order_effects(self.xTrain, self.order)\n",
        "\t\t(nSamps, nCoeffs) = self.xTrain.shape\n",
        "\n",
        "\t\t# check if x_train contains columns with zeros or duplicates\n",
        "\t\t# and find the corresponding indices\n",
        "\t\tcheck_zero = np.all(self.xTrain == np.zeros((nSamps,1)), axis=0)\n",
        "\t\tidx_zero   = np.where(check_zero == True)[0]\n",
        "\t\tidx_nnzero = np.where(check_zero == False)[0]\n",
        "\n",
        "\t\t# remove columns of zeros in self.xTrain\n",
        "\t\tif np.any(check_zero):\n",
        "\t\t\tself.xTrain = self.xTrain[:,idx_nnzero]\n",
        "\n",
        "\t\t# run Gibbs sampler for nGibbs steps\n",
        "\t\tattempt = 1\n",
        "\t\ttrial = 100\n",
        "\t\twhile(attempt):\n",
        "\n",
        "\t\t\t# re-run if there is an error during sampling\n",
        "\t\t\ttry:\n",
        "\t\t\t\talphaGibbs,a0,_,_,_ = bhs(self.xTrain,self.yTrain,nGibbs,0,1)\n",
        "\t\t\texcept:\n",
        "\t\t\t\tprint('error during Gibbs sampling. Trying again.')\n",
        "\t\t\t\ttrial -= 1\n",
        "\t\t\t\tif trial > 0:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\traise TimeoutError\n",
        "\n",
        "\t\t\t# run until alpha matrix does not contain any NaNs\n",
        "\t\t\tif not np.isnan(alphaGibbs).any():\n",
        "\t\t\t\tattempt = 0\n",
        "\t\t\t\n",
        "\t\t# append zeros back - note alpha(1,:) is linear intercept\n",
        "\t\talpha_pad = np.zeros(nCoeffs)\n",
        "\t\talpha_pad[idx_nnzero] = alphaGibbs[:,-1]\n",
        "\t\tself.alpha = np.append(a0, alpha_pad)\n",
        "\n",
        "\t# ---------------------------------------------------------\n",
        "\t# ---------------------------------------------------------\n",
        "\n",
        "\tdef predict(self, x):\n",
        "\t\t# Old name: surrogate_model(self, x, alpha): ...\n",
        "\t\t\n",
        "\t\t# SURROGATE_MODEL: Function evaluates the linear model\n",
        "\t\t# Assumption: input x only contains one row -- loosen by HanseulJo\n",
        "\n",
        "\t\t# generate x_all (all basis vectors) based on model order\n",
        "\t\t#x_all = np.append(1, self.order_effects(x, self.order))\n",
        "\t\talpha = self.alpha\n",
        "\n",
        "\t\tx_all = PolynomialFeatures(degree=self.order, interaction_only=True).fit_transform(x)\n",
        "\n",
        "\t\t# check if x maps to an Inf output (if so, barrier=Inf)\n",
        "\t\tbarrier = 0.\n",
        "\t\tif self.xInf.shape[0] != 0:\n",
        "\t\t\tif np.equal(x, self.xInf).all(axis=1).any():\n",
        "\t\t\t\tbarrier = np.inf\n",
        "\n",
        "\t\t# compute and return objective with barrier\n",
        "\t\tout = x_all @ alpha.reshape((-1,1)) + barrier\n",
        "\t\t\n",
        "\t\treturn out.reshape(-1)\n",
        "\n",
        "\n",
        "\t# ---------------------------------------------------------\n",
        "\t# ---------------------------------------------------------\n",
        "\n",
        "\tdef order_effects(self, x_vals, ord_t):\n",
        "\t\t# order_effects: Function computes data matrix for all coupling\n",
        "\t\t# orders to be added into linear regression model.\n",
        "\n",
        "\t\t# Find number of variables\n",
        "\t\tn_samp, n_vars = x_vals.shape\n",
        "\n",
        "\t\t# Generate matrix to store results\n",
        "\t\tx_allpairs = x_vals\n",
        "\n",
        "\t\tfor ord_i in range(2,ord_t+1):\n",
        "\n",
        "\t\t\t# generate all combinations of indices (without diagonals)\n",
        "\t\t\toffdProd = np.array(list(combinations(np.arange(n_vars),ord_i)))\n",
        "\n",
        "\t\t\t# generate products of input variables\n",
        "\t\t\tx_comb = np.zeros((n_samp, offdProd.shape[0], ord_i))\n",
        "\t\t\tfor j in range(ord_i):\n",
        "\t\t\t\tx_comb[:,:,j] = x_vals[:,offdProd[:,j]]\n",
        "\t\t\tx_allpairs = np.append(x_allpairs, np.prod(x_comb,axis=2),axis=1)\n",
        "\n",
        "\t\treturn x_allpairs\n",
        "\n",
        "\n",
        "# -- END OF FILE --"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUC-hDHYTcPM"
      },
      "source": [
        "def flip(state, ind):\n",
        "    \"\"\" given a state (in numpy array), flip (0 <-> 1) a digit \"\"\"\n",
        "    assert state.ndim == 1, state.ndim\n",
        "    new_state = state.copy()\n",
        "    new_state[ind] = 1-new_state[ind]\n",
        "    return new_state\n",
        "\n",
        "def neighbors(state):\n",
        "    \"\"\" given a state (in numpy array), return a 2D array whose rows are neighbors of the state \"\"\"\n",
        "    return np.stack([flip(state, i) for i in range(len(state))])\n",
        "\n",
        "def hamming_dist(start, end):\n",
        "    assert start.ndim == end.ndim == 1 , (start.ndim, end.ndim)\n",
        "    assert start.size == end.size, (start.size, end.size)\n",
        "    return (start != end).sum()\n",
        "\n",
        "def is_reachable(start, end, flips):\n",
        "    return (start + end).sum() % 2 == flips % 2 and hamming_dist(start,end) <= flips\n",
        "\n",
        "def path(start, end, flips):\n",
        "    assert is_reachable(start, end, flips)\n",
        "    if flips == 0:\n",
        "        return np.array([[]])\n",
        "    N = start.size\n",
        "    diff = start != end\n",
        "    flip_inds = np.arange(N)[diff]\n",
        "    if flips > diff.sum():\n",
        "        assert (flips-diff.sum()) % 2 == 0\n",
        "        n = (flips-diff.sum()) // 2\n",
        "        flip_inds = np.append(flip_inds, np.tile(np.random.choice(N, n), 2))\n",
        "    np.random.shuffle(flip_inds)\n",
        "    return flip_inds\n",
        "\n",
        "def wander(start, flips):\n",
        "    assert start.ndim == 1 and flips % 2 == 0\n",
        "    n = flips // 2\n",
        "    flip_inds = np.arange(start.shape[0])\n",
        "    np.random.shuffle(flip_inds)\n",
        "    flip_inds = np.tile(flip_inds[:n], 2)\n",
        "    return flip_inds\n",
        "\n",
        "def is_visited(x_vals, x_new):\n",
        "    assert x_new.ndim == 1, x_new.ndim\n",
        "    return np.all(x_new == x_vals, axis=1).any()\n",
        "\n",
        "def states(N):\n",
        "    return np.stack([np.array(tup) for tup in itertools.product(range(2), repeat=N)])\n",
        "\n",
        "# add new data\n",
        "def add_data(inputs, x, y):\n",
        "  assert len(y) == 1\n",
        "  inputs['x_vals'] = np.vstack((inputs['x_vals'], x))\n",
        "  inputs['y_vals'] = np.hstack((inputs['y_vals'], y))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKHIazX8vZ2x"
      },
      "source": [
        "def random_next(x_vals, curr_x=None):\n",
        "    \"\"\"\n",
        "    RANDOM NEXT index to flip, but avoid visited nbh as much as possible\n",
        "    \"\"\"\n",
        "    if curr_x is None:\n",
        "        curr_x = x_vals[-1]\n",
        "    num_nbh = curr_x.shape[0]  # N\n",
        "    nbh_inds = np.arange(num_nbh)\n",
        "    np.random.shuffle(nbh_inds)\n",
        "    i_ = 0\n",
        "    while i_ < num_nbh:\n",
        "        flip_ind = nbh_inds[i_]\n",
        "        if not is_visited(x_vals, flip(curr_x.reshape(-1), flip_ind)):\n",
        "            break\n",
        "        else:\n",
        "            i_ += 1\n",
        "    if i_ == num_nbh:\n",
        "        flip_ind = np.random.randint(num_nbh)\n",
        "    return flip_ind\n",
        "    \n",
        "\n",
        "def monitor_reachable_best(x_vals, y_vals, t, n_eval, show_objective_x=False):\n",
        "    \"\"\"\n",
        "    Return a PATH to Reachable-best (and the value of R-best)\n",
        "    \"\"\"\n",
        "    curr_x = x_vals[-1]\n",
        "    left_chance = n_eval - t\n",
        "    y_sort_ind = np.argsort(-y_vals)  # positive: min -y ~= max fitness\n",
        "    PATH = None\n",
        "    for j in y_sort_ind:\n",
        "        objective_x = x_vals[j]\n",
        "        objective_y = y_vals[j]\n",
        "        if is_reachable(curr_x, objective_x, left_chance):\n",
        "            PATH = path(curr_x, objective_x, left_chance)\n",
        "            break\n",
        "    if show_objective_x:\n",
        "        return PATH, objective_y, objective_x\n",
        "    return PATH, objective_y\n",
        "\n",
        "\n",
        "def stochastic_ascent(stat_model, x_vals, max_flips, visit_weight, calculated_acqs=None):\n",
        "    \"\"\"\n",
        "    Stochastic Ascent of Acquisition.\n",
        "    \"\"\"\n",
        "    assert max_flips > 0\n",
        "    x_vals = x_vals.copy()\n",
        "    x = x_vals[-1]\n",
        "    N = x.shape[0]\n",
        "\n",
        "    for flip_ in range(1,max_flips+1):\n",
        "        x_nbrs = neighbors(x)\n",
        "        \n",
        "        # evaluate acquisitions\n",
        "        if calculated_acqs is None:\n",
        "            nbrs_acquisition = np.array([stat_model(x_nbrs[i].reshape((1,-1))) for i in range(N)])\n",
        "        else:\n",
        "            nbrs_to_bin = [x_nbrs[i].dot(1 << np.arange(N)[::-1]) for i in range(N)]\n",
        "            nbrs_acquisition = np.array([calculated_acqs[b] for b in nbrs_to_bin])\n",
        "\n",
        "        # convert to probability (less acq, more prob)\n",
        "        m_ = nbrs_acquisition.min()\n",
        "        score = nbrs_acquisition.copy()\n",
        "        if m_ < 0:\n",
        "            score -= m_ # make all scores non negative\n",
        "        vw = visit_weight(max_flips+1-flip_)\n",
        "        for i in range(N):\n",
        "            if is_visited(x_vals, x_nbrs[i]):\n",
        "                score[i] *= vw  # give weight by a num <= 1 to visited vertex\n",
        "        score_stand = softmax(score*3)  # multiplying 3: just for appropriate scaling\n",
        "        #print(score_stand)\n",
        "\n",
        "        # update x\n",
        "        next_ind = int(np.random.choice(np.arange(N), p=score_stand))\n",
        "        x = x_nbrs[next_ind]\n",
        "        x_vals = np.concatenate((x_vals, x.reshape((1,-1))))\n",
        "\n",
        "    return nbrs_acquisition[next_ind]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKiXA_zYNHOI"
      },
      "source": [
        "surrogate_model_dict = {\n",
        "    'BOCS':      LinReg(order=2),\n",
        "    'PolyReg':   Pipeline([('poly', PolynomialFeatures(interaction_only=True)), ('linear', LinearRegression())]),\n",
        "    'PolyLasso': Pipeline([('poly', PolynomialFeatures(interaction_only=True)), ('linear', Lasso())]),\n",
        "}\n",
        "\n",
        "def neighbor_suggestion(args, stat_model, inputs, max_flips, trials=10, tqdm_on=False, calculated_acqs=None, return_scores=False):\n",
        "    assert max_flips > 0\n",
        "\n",
        "    x_vals = inputs['x_vals'].copy()\n",
        "    x = x_vals[-1]\n",
        "    N = args.N\n",
        "    x_nbrs = neighbors(x)\n",
        "\n",
        "    # visited penalty\n",
        "    n_eval = args.n_eval\n",
        "    visit_weight = lambda fl: (n_eval - fl)/(n_eval - N) if fl>N else 1.\n",
        "    vw = visit_weight(max_flips)\n",
        "\n",
        "    if max_flips == 1:\n",
        "        if calculated_acqs is None:\n",
        "            ascent_scores = [stat_model(x_nbrs[i].reshape((1,-1))) for i in range(N)]\n",
        "        else:\n",
        "            nbrs_to_bin = [x_nbrs[i].dot(1 << np.arange(N)[::-1]) for i in range(N)]  # change x_nbrs[i]=array([0,0,1,0,1,1]) into integer 11.\n",
        "            ascent_scores = [calculated_acqs[b] for b in nbrs_to_bin]\n",
        "    elif max_flips > 1:\n",
        "        ascent_scores = []\n",
        "        it = tqdm(range(N), desc=f\"Stochastic Ascent from {x}\") if tqdm_on else range(N)\n",
        "        for i in it:\n",
        "            if calculated_acqs is None:\n",
        "                _asc = [stochastic_ascent(stat_model, np.vstack((x_vals, x_nbrs[i])), max_flips-1, visit_weight) for _ in range(trials)]\n",
        "            else:\n",
        "                _asc = [stochastic_ascent(stat_model, np.vstack((x_vals, x_nbrs[i])), max_flips-1, visit_weight, calculated_acqs=calculated_acqs) for _ in range(trials)]\n",
        "            ascent_scores.append(sum(_asc)/trials)  # average\n",
        "        for i in range(N):\n",
        "            if is_visited(x_vals, x_nbrs[i]):\n",
        "                ascent_scores[i] *= vw  # give weight by a num <= 1\n",
        "    \n",
        "    ascent_scores = np.array(ascent_scores)\n",
        "    if return_scores:\n",
        "        return ascent_scores\n",
        "\n",
        "    best_nbr_ind = np.argmax(ascent_scores)\n",
        "    return best_nbr_ind"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8ohWTnfkf9V"
      },
      "source": [
        "def _show_best(best):\n",
        "    print(\"*** Displaying Your Best Attempt So Far ***\")\n",
        "    for key in best:\n",
        "        print(\"best\", key, \":\", best[key])\n",
        "\n",
        "def _show_all(inputs):\n",
        "    print(\"*** Displaying All Your Attempt So Far (state --> score) ***\")\n",
        "    x_vals, y_vals = inputs['x_vals'], inputs['y_vals']\n",
        "    for i in range(y_vals.size):\n",
        "        print(f\"Round{i:02d}: {x_vals[i]} --> {y_vals[i]:.4f}\")\n",
        "\n",
        "def _yes_or_no():\n",
        "    \"\"\"\n",
        "    example:\n",
        "    if _yes_or_no():\n",
        "        pass\n",
        "    \"\"\"\n",
        "    YORN = 'undefined'\n",
        "    while True:\n",
        "        YORN = input(\"yes[y] or no[n]: \").strip()\n",
        "        if len(YORN) <= 0:\n",
        "            continue\n",
        "        if YORN.lower()[0] in ['y', 'n']:\n",
        "            break\n",
        "    return YORN.lower()[0] == 'y'\n",
        "\n",
        "\n",
        "def input_start_point(N):\n",
        "    print(f\"\\nNK MODEL GAME MODE ON\\n\")\n",
        "    print(f\"Before start, write {N} numbers: each number should be 0 or 1.\")\n",
        "    print(f\"Separate numbers by ' '(spacebar).\")\n",
        "    INPUT = []\n",
        "    error_str=None\n",
        "    while len(INPUT) != N or not set(INPUT).issubset(set(['0', '1'])):\n",
        "        INPUT = input(\"* Your input: \").strip().split()\n",
        "        if len(INPUT) != N:\n",
        "            print(f\"Wrong length: write {N} numbers and separate with spacebars.\")\n",
        "        if not set(INPUT).issubset(set(['0', '1'])):\n",
        "            print(\"Wrong number: write 0 or 1 only\")\n",
        "    init_x = np.array([int(x) for x in INPUT])\n",
        "    return init_x\n",
        "\n",
        "\n",
        "def player_decision(N, inputs, best, next_x):\n",
        "    print( \"NOW: Which digit do YOU want to flip?\")\n",
        "    print(f\"     Write a number m if you want to flip m-th digit: (1 <= m <= {N})\")\n",
        "    print(f\"     Or, write 'BEST' if you want to display the BEST results so far\")\n",
        "    print(f\"     Or, write 'history' if you want to display the ALL your attempts so far\")\n",
        "    while True:\n",
        "        flip_idx = None\n",
        "        while flip_idx not in range(1, N+1):\n",
        "            INPUT = input(\"* Your input: \").strip()\n",
        "            if INPUT == 'BEST':\n",
        "                _show_best(best)\n",
        "            elif INPUT == 'history':\n",
        "                _show_all(inputs)\n",
        "            elif INPUT.isdigit():\n",
        "                flip_idx = int(INPUT)\n",
        "                if flip_idx not in range(1, N+1):\n",
        "                    print(f\"Wrong number: Write a number from 1 to {N}: \")\n",
        "            else:\n",
        "                print(\"Wrong input format: Write again: \")\n",
        "        flip_idx -= 1  # index: 0 ~ N-1\n",
        "        print(\"Do you really want to change the state as follows?:\")\n",
        "        print(\">> FROM :\", next_x)\n",
        "        print(\">>   TO :\", flip(next_x, flip_idx))\n",
        "        if _yes_or_no():\n",
        "            return flip_idx\n",
        "        else:\n",
        "            print(\"You answered NO: Re-write your input. \")\n",
        "            print( \"NOW: Which digit do U wanna flip?\")\n",
        "            print(f\"     Write a number m if you want to flip m-th digit: (1 <= m <= {N})\")\n",
        "            print(f\"     Or, Write 'BEST' if you wnat to display the BEST results so far\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBnjqp0Bo6BF"
      },
      "source": [
        "def GAME(args, chances=None, show_interdependence=False, can_restart=False, surrogate_model_name='PolyReg', back_to_best=False, ascent_trial=64):\n",
        "\n",
        "    print(\"Preparing the game.....\")\n",
        "\n",
        "    assert surrogate_model_name in ['BOCS', 'PolyReg', 'PolyLasso']\n",
        "\n",
        "    N = args.N\n",
        "    if chances is None:\n",
        "        chances = args.n_eval\n",
        "    elif chances != args.n_eval:\n",
        "        print(\"args.n_eval changed:\", chances)\n",
        "        args.n_eval = chances\n",
        "    all_states = states(N)\n",
        "    \n",
        "    # Construct NKmodel\n",
        "    nkmodel = Construct_NKmodel(args)\n",
        "    optimum, _, _landscape = nkmodel.get_global_optimum(cache=True)\n",
        "    optlist = nkmodel.get_optimum_and_more(2**N)\n",
        "    if show_interdependence:\n",
        "        print(nkmodel.interdependence) # Boolean interdependence matrix\n",
        "\n",
        "    start = True\n",
        "    while start:\n",
        "        init_x = input_start_point(N)\n",
        "        init_y = nkmodel.evaluate(init_x)\n",
        "        inputs = {'x_vals': init_x.reshape(1,-1), 'y_vals': init_y}\n",
        "        \n",
        "        best = {'x': init_x.copy(), 'y': float(init_y), 'round': 1}  # store so far best result\n",
        "        \n",
        "        # Surrogate model\n",
        "        LR = surrogate_model_dict[surrogate_model_name]\n",
        "        \n",
        "        fit_diff = 0                # fitness  difference (previous --> current)       \n",
        "        ctrbs_diff = np.zeros(N)    # contrib. difference (previous --> current)\n",
        "\n",
        "        next_x = init_x.copy()\n",
        "        next_y = init_y\n",
        "        PATH = None\n",
        "        print()\n",
        "        for ROUND in range(1, chances+1):\n",
        "            print(f\"*** Round {ROUND}/{chances} ***\")\n",
        "            print( \"Previous results:\")\n",
        "            print( \"Current state:\", next_x, '<== IMPROVED' if ROUND>1 and np.all(best['x'] == next_x) else '')\n",
        "            print(f\"Current fitness: {float(next_y):.4f} ({fit_diff:.4f} from before)\")\n",
        "            print( \"Current improvement of contributions:\", ctrbs_diff)\n",
        "            print()\n",
        "\n",
        "            # Flip-index suggestion\n",
        "            left_chance = chances - ROUND + 1\n",
        "            if PATH is None:\n",
        "                if ROUND > 1:\n",
        "                    stat_model = lambda x: LR.predict(x.reshape(1,N))[0]\n",
        "                    acqs_ = LR.predict(all_states)\n",
        "                    ascent_score = neighbor_suggestion(args, stat_model, inputs, left_chance, trials=ascent_trial, tqdm_on=True, calculated_acqs=acqs_, return_scores=True)\n",
        "                    flip_suggest = ascent_score.argmax()\n",
        "                else: # ROUND == 1\n",
        "                    ascent_score = np.ones(N) / 2        # uniformly random suggestion\n",
        "                    flip_suggest = np.random.randint(6)\n",
        "                print(f\"### The ALGORITHM says *<<{flip_suggest+1}-th>>* is the best position to flip, because...\")\n",
        "                for i in range(6):\n",
        "                    print(f\"### the value of flipping {i+1}-th position is {ascent_score[i]:.4f};\")\n",
        "            elif back_to_best:\n",
        "                flip_suggest = PATH[-left_chance]\n",
        "                print(f\"### The ALGORITHM says *<<{flip_suggest+1}-th>>* is the best position to flip, because...\")\n",
        "                print(f\"### You are ON A WAY to go back to the so-far-best (reachable) state !:\", objective_x)\n",
        "            print()\n",
        "            \n",
        "\n",
        "            # Flip-index Choice (by Player)\n",
        "            flip_idx = player_decision(N, inputs, best, next_x)\n",
        "            \n",
        "            # Compute next state / fitness / contribution improvement\n",
        "            next_y_temp, ctrbs_diff = nkmodel.fitness_and_contrib_diff(next_x, flip_idx)\n",
        "            next_x = flip(next_x, flip_idx)\n",
        "            fit_diff = next_y_temp - float(next_y)\n",
        "            next_y = np.array([next_y_temp])\n",
        "\n",
        "            # inputs update\n",
        "            add_data(inputs, next_x, next_y)\n",
        "            \n",
        "\n",
        "            if back_to_best and (ROUND >= chances - N):\n",
        "                # If the player did different action from the suggestion, initialize PATH\n",
        "                if flip_suggest != flip_idx:\n",
        "                    PATH = None \n",
        "\n",
        "                # Possibly, update PATH (if it exists)\n",
        "                if (PATH is not None) and (left_chance-1>0) and ((left_chance-1) % 2 == 0) and (next_y > objective_y):  # new reachable best --> update PATH\n",
        "                    PATH[-(left_chance-1):] = wander(next_x, left_chance-1)\n",
        "            \n",
        "                # At some point, we should save a PATH to reachable best so far.\n",
        "                if PATH is None: \n",
        "                    PATH, objective_y, objective_x = monitor_reachable_best(inputs['x_vals'], inputs['y_vals'], ROUND, chances, show_objective_x=True)\n",
        "                    print(\"*#*#* Notice: From now, your on the way to go back to the state:\", objective_x)\n",
        "                    print(\"*#*#* Of course, you may take different way from the algorithm's suggestion! \")\n",
        "                    time.sleep(0.5)\n",
        "            \n",
        "            # surrogate model train\n",
        "            LR.fit(inputs['x_vals'], inputs['y_vals'])\n",
        "\n",
        "            # best state update\n",
        "            if next_y > best['y']:\n",
        "                best[\"y\"] = next_y\n",
        "                best[\"x\"] = next_x\n",
        "                best[\"round\"] = ROUND\n",
        "            print(\"\\n\"+\"=\"*100+\"\\n\")\n",
        "        \n",
        "        time.sleep(2)\n",
        "        print(\"THE END: All the chances Ran out!\")\n",
        "        print(\"Finally, your best attempt is:\")\n",
        "        _show_best(best)\n",
        "        print()\n",
        "\n",
        "        print(\"Also, your FINAL attempt is:\")\n",
        "        print(\"*** Displaying Your Final Score ***\")\n",
        "        print(\"final x :\", next_x)\n",
        "        print(\"final y :\", next_y)\n",
        "        print()\n",
        "\n",
        "        # Compute reachable best\n",
        "        reachable_best = None\n",
        "        for ind in range(len(optlist)):\n",
        "            opt, optstates = optlist[ind][\"fitness\"], optlist[ind][\"states\"]\n",
        "            for st in optstates:\n",
        "                if is_reachable(init_x, np.array(st), chances):\n",
        "                    reachable_best = opt\n",
        "                    break\n",
        "            if reachable_best is not None:\n",
        "                break\n",
        "\n",
        "        time.sleep(2)\n",
        "        # Assesment of result\n",
        "        if abs(float(next_y) - optimum) <= 1e-5:\n",
        "            print(\"You have reached the global optimum !!! You made it !!!\")\n",
        "            start = False\n",
        "        else:\n",
        "            print(\"You did not reached the global optimum.\")\n",
        "            if abs(float(next_y) - reachable_best) <= 1e-5:\n",
        "                print(\"However, you did your best!! (Your final answer is 'reachable-optimum')\")\n",
        "                start = False\n",
        "            else:\n",
        "                print(\"Well, everyone has their bad days.\")\n",
        "        print()\n",
        "        \n",
        "        # Ask whether to restart\n",
        "        start = start and can_restart\n",
        "        time.sleep(3)\n",
        "        if start:\n",
        "            print(\"Do you want to try again? (with the same landscape)\")\n",
        "            if _yes_or_no():\n",
        "                print(\"Caution: your best score will be removed from the memory\\n\")\n",
        "            else:\n",
        "                start = False\n",
        "        \n",
        "        # Scoreboard\n",
        "        if not start:\n",
        "            print(\"Do you want to see the score board? (Caution: It will print 64-line results.\")\n",
        "            if _yes_or_no():\n",
        "                for i in range(len(optlist)):\n",
        "                    opt, optstates = optlist[i][\"fitness\"], optlist[i][\"states\"]\n",
        "                    print(f\"{i+1}-th optimum: {opt:.5f} {optstates}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jxRRmdHpGEs"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VblZatbpUIO"
      },
      "source": [
        "args = EasyDict()\n",
        "\n",
        "args.random_seed = 2021\n",
        "args.n_eval = 18\n",
        "args.n_init = 2\n",
        "args.N = 6\n",
        "args.K = 1\n",
        "args.A = 2\n",
        "args.terminal_size = 50\n",
        "\n",
        "np.set_printoptions(precision=3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLME01MWidJa"
      },
      "source": [
        "# Play a GAME!\n",
        "\n",
        "* surrogate_model_name은 'BOCS', 'PolyReg', 'PolyLasso' 중에서 고를 수 있습니다. 속도와 정확성을 위해 PolyReg 또는 PolyReg를 추천합니다. (BOCS가 4배 정도 느립니다.)\n",
        "* back_to_best는 True, False 중에서 고를 수 있으며, True 이면 Back-to-Reachable-Best Heuristic을 마지막 N=6번에 적용합니다. False를 추천합니다.\n",
        "* ascent_trial은 아무런 자연수를 넣어도 됩니다. 작을수록 빠르지만 부정확하며, 클수록 느리지만 정확합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctJfYzToJx5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "a3ba67dd-daea-4c1b-ca88-2125e81e4e1e"
      },
      "source": [
        "GAME(args, chances=18, show_interdependence=False, surrogate_model_name='PolyReg', back_to_best=False, ascent_trial=64)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing the game.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-015f7711da93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_interdependence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PolyReg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_to_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-9220cb6f38f2>\u001b[0m in \u001b[0;36mGAME\u001b[0;34m(args, chances, show_interdependence, can_restart, surrogate_model_name, back_to_best, ascent_trial)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args.n_eval changed:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mall_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Construct NKmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0e5d4f3ef5ba>\u001b[0m in \u001b[0;36mstates\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# add new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'product' is not defined"
          ]
        }
      ]
    }
  ]
}